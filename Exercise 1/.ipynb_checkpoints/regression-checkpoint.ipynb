{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<center>\n",
    "<a href=\"https://www.vision.rwth-aachen.de/\"><img src=\"data:image/png;base64,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\" alt=\"Vision Institute i13\" width=\"320\"/></a>\n",
    "</center>\n",
    "\n",
    "# Advanced Machine Learning Excercises\n",
    "\n",
    "**Assistants:**\\\n",
    "Alexey Nekrasov \\<nekrasov@vision.rwth-aachen.de\\>\\\n",
    "Jens Piekenbrinck \\<piekenbrinck@vision.rwth-aachen.de\\>\n",
    "\n",
    "The assignments are **NOT** mandatory, but we still encourage you to work on them, in order to gain a deeper understanding.\n",
    "\n",
    "We want to provide you with an interactive learning experience, so the assignments rely on [Jupyter](https://jupyter.org/) notebooks which you can run locally on your computer. The RWTH also offers a [JupyterHub](jupyter.rwth-aachen.de/) where you can run notebooks. If you have any questions, please contact us.\n",
    "\n",
    "Make sure you fill in any place in *code cells* that says:\n",
    "```python\n",
    "# YOUR CODE HERE\n",
    "raise NotImplementedError()\n",
    "```\n",
    "\n",
    "Make sure you fill in any place in *text cells* that says:\\\n",
    "`YOUR ANSWER HERE`\n",
    "\n",
    "Upload all the notebook files with your changes to moodle. **IMPORTANT**: Do not rename files.\n",
    "\n",
    "‚è∞ Due date: 2022-04-26 23:59:00"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 1: Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Bayesian Inferencing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Assume that training data points $\\mathbf{X}=[\\mathbf{x}_1,\\ldots,\\mathbf{x}_N]\\in\\mathbb{R}^{d\\times N}$ and corresponding scalar target values $\\mathbf{t}=[t_1,\\ldots,t_N]^\\text{T}$ are drawn independently with a likelihood in the form \n",
    "$$\\begin{aligned} p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{w},\\beta)=\\prod_{n=1}^N\\mathcal{N}(t_n\\vert\\mathbf{w}^\\text{T}\\mathbf{\\phi}(\\mathbf{x}_n), \\beta^{-1})\n",
    "\\end{aligned}$$ \n",
    "for parameters $\\mathbf{w}$ and $\\beta$. Let a Gaussian prior over the coefficients $\\mathbf{w}$ be given by\n",
    "$$\\begin{aligned}\n",
    "        p(\\mathbf{w}|\\alpha)=\\mathcal{N}(\\mathbf{w}\\vert\\mathbf{0},\\alpha^{-1}\\mathbf{I}).\n",
    "\\end{aligned}$$ \n",
    "Under these assumptions it can be shown that the resulting posterior distribution \n",
    "\n",
    "$$\\begin{aligned}\n",
    "            p(\\mathbf{w}|\\mathbf{X},\\mathbf{t},\\beta,\\alpha)\\propto p(\\mathbf{t}\\vert\\mathbf{X},\\mathbf{w},\\beta) p(\\mathbf{w}|\\alpha)\n",
    "\\end{aligned}$$ \n",
    "is again a Gaussian, wherefore the prior and posterior distributions are called *conjugate*. Show that the mean $\\pmb{\\mu}_N$ and variance $\\mathbf{\\Sigma}_N$ of the posterior distribution are given by \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    \\pmb{\\mu}_N=\\beta\\mathbf{\\Sigma}_N\\mathbf{\\Phi}^\\text{T}\\mathbf{t}\\quad\\text{and}\\quad\\mathbf{\\Sigma}_N^{-1}=\\alpha\\mathbf{I}+\\beta\\mathbf{\\Phi}^\\text{T}\\mathbf{\\Phi}.\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "745f6a0a9788bf630dd56d6b05b21501",
     "grade": true,
     "grade_id": "q1a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution (Question 1.a)\n",
    "$$\\begin{aligned}\n",
    "    \\sum_{x}^{y}\\to \\longleftarrow \\cup \\subset \\bigcup_{\\Theta\\Delta\\Gamma\\Sigma\\Sigma\\Phi}^{}\n",
    "\\end{aligned}$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) The posterior in part (a) can be regarded as the prior for the next observation. By considering an additional data point $(\\mathbf{x}_{N+1}, t_{N+1})$, show that the resulting posterior distribution takes again the above form but with $N$ replaced by $N+1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "8aac2d78a4d98f0c3730793dcc330dd0",
     "grade": true,
     "grade_id": "q1b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Loss Functions For Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Consider the expected loss\n",
    "\n",
    "$$\\begin{aligned}\n",
    "        \\mathbb{E}[L_q]=\\int_{\\mathbb{R}^d}\\int_\\mathbb{R}L_q(t,y(\\mathbf{x}))p(\\mathbf{x},t)\\text{d}t\\text{d}\\mathbf{x}\n",
    "\\end{aligned}$$ \n",
    "for the *Minkowski loss* function $L_q(t,y(\\mathbf{x}))=\\vert y(\\mathbf{x})-t\\vert^q$. In the lecture you have seen that the optimal regression function $y:\\mathbb{R}^d\\rightarrow\\mathbb{R}$ that minimizes $\\mathbb{E}[L_q]$ for the squared loss $q=2$ is given by the *conditional mean* $y(\\mathbf{x})=\\mathbb{E}[t\\vert\\mathbf{x}]=\\int_\\mathbb{R}tp(t\\vert\\mathbf{x})\\text{d}t$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(a) Show that for $q=1$ the optimal regression function is given by the *conditional median* \n",
    "$$\\begin{aligned}\n",
    "    y(\\mathbf{x})=\\mathop{\\mathrm{argmin}}_{\\hat y}\\int_\\mathbb{R}\\vert\\hat y -t\\vert p(t\\vert\\mathbf{x})\\text{d}t\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "f61def65e76bf70c7fa5de79e3963ef7",
     "grade": true,
     "grade_id": "q2a",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "(b) Show that for $q\\rightarrow 0$ the optimal regression function is given\n",
    "by the *conditional mode* \n",
    "\n",
    "$$\\begin{aligned}\n",
    "    y(\\mathbf{x})=\\mathop{\\mathrm{argmax}}_{t\\in\\mathbb{R}}p(t\\vert\\mathbf{x})\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "markdown",
     "checksum": "5691061b5df12b631adb3c499ecd7b03",
     "grade": true,
     "grade_id": "q2b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "YOUR ANSWER HERE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Least Squares Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem your task is to learn a function, $f: \\mathbb{R} \\rightarrow \\mathbb{R}$, given the training data using least squares regression.\n",
    "\n",
    "You will use the datasets `test.txt` and `train.txt`, in which the data matrices contain 1D data points $x_i \\in \\mathbb{R}$ in the first column and the corresponding target output values $y_i \\in \\mathbb{R}$ in the second column.\n",
    "\n",
    "Instead of the polynomial basis functions discussed in class, here you will use the Fourier basis functions: $$\\begin{aligned}\n",
    "        \\phi_0(x) = 1\n",
    "        \\hspace{1cm}  \\phi_{2l-1}(x) = \\frac{1}{l} \\text{cos}(2\\pi l x)\n",
    "        \\hspace{1cm}  \\phi_{2l}(x) = \\frac{1}{l} \\text{sin}(2\\pi l x)\n",
    "\\end{aligned}$$ \n",
    "where $l\\ (l = 1,2,3,\\ldots)$ is the frequency of the basis function. \n",
    "\n",
    "Thus, given the maximal frequency $k$, we will have $2k+1$ basis functions. \n",
    "\n",
    "For a fixed maximal frequency $k$, every data pair $(x_i, y_i),\\ i=1,\\ldots,N,$ defines an equation $$\\begin{aligned}\n",
    "        w_0\\cdot\\phi_0(x_i)+w_1\\cdot\\phi_1(x_i)+\\cdots+w_{2k}\\cdot\\phi_{2k}(x_i)=y_i\n",
    "    \\end{aligned}$$ with coefficients $w_0,\\ldots,w_{2k}\\in\\mathbb{R}$.\n",
    "    \n",
    "Writing them into a single matrix equation, we get \n",
    "$$\\begin{aligned}\n",
    "        \\underbrace{\\begin{bmatrix}\n",
    "            \\phi_0(x_0) & \\phi_1(x_0) & \\cdots & \\phi_{2k}(x_0) \\\\\n",
    "            \\phi_0(x_1) & \\phi_1(x_1) & \\cdots & \\phi_{2k}(x_1) \\\\\n",
    "            \\vdots & \\vdots & \\vdots & \\vdots\\\\\n",
    "            \\phi_0(x_N) & \\phi_1(x_N) & \\cdots & \\phi_{2k}(x_N)\n",
    "        \\end{bmatrix}}_{\\mathbf{\\Phi}}\n",
    "        \\cdot\n",
    "        \\underbrace{\\begin{bmatrix}\n",
    "            w_0\\\\\n",
    "            w_1\\\\\n",
    "            \\vdots\\\\\n",
    "            w_{2k}\n",
    "        \\end{bmatrix}}_{\\mathbf{w}}\n",
    "        =\n",
    "        \\underbrace{\\begin{bmatrix}\n",
    "            y_0\\\\\n",
    "            y_1\\\\\n",
    "            \\vdots\\\\\n",
    "            y_N\n",
    "        \\end{bmatrix}}_{\\mathbf{y}}.\n",
    "\\end{aligned}$$ \n",
    "Since the system $\\mathbf{\\Phi}\\cdot\\mathbf{w}=\\mathbf{y}$ is usually overconstrained, it does not have an exact solution.\n",
    "\n",
    "Instead, we consider the solution to the minimization problem \n",
    "$$\\begin{aligned}\n",
    "        \\lVert\\mathbf{\\Phi}\\cdot\\mathbf{w}-\\mathbf{y}\\rVert^2\\rightarrow\\min,\n",
    "\\end{aligned} $$\n",
    "which is given by the *normal equations* $\\mathbf{w}=(\\mathbf{\\Phi}^\\text{T}\\mathbf{\\Phi})^{-1}\\mathbf{\\Phi}^\\text{T}\\mathbf{y}$.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.a: Plot the data and compute fourier features\n",
    "Load the data `train.txt` and use least squares regression to fit functions $f_k$ with the maximal frequency $k=1,3,5,\\ldots,17$.\n",
    "Plot the $9$ resulting functions together with the training data into a single figure.\n",
    "Explain the effect of the increasing $k$ on the fitting function $f_k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = np.genfromtxt(\"train.txt\")\n",
    "train_X, train_y = train[:, 0], train[:, 1]\n",
    "test = np.genfromtxt(\"test.txt\")\n",
    "test_X, test_y = test[:, 0], test[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "plt.plot(test_X, test_y, \"bo\")\n",
    "plt.plot(train_X, train_y, \"rx\")\n",
    "plt.legend([\"test\", \"train\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d7fc4b33ed60eaf5cdf2cc9489b2f504",
     "grade": false,
     "grade_id": "fourier_features",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def fourier_features(x, n):\n",
    "    \"\"\"\n",
    "    Produces fourier features for the input.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        input array of shape (N,).\n",
    "    n : int\n",
    "        feature dimensionality.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    x_tilda : array_like\n",
    "        resulting fourier features of shape (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # read the task\n",
    "    # YOUR CODE HERE\n",
    "    #temp = []\n",
    "    temp = np.zeros((np.shape(x)))\n",
    "    i = 0\n",
    "    for xx in x: \n",
    "        if n==0:\n",
    "            temp[i] = 1\n",
    "        elif n%2 != 0:\n",
    "            temp[i] = (2/(n+1)) * np.cos(2*np.pi*(n+1)*xx/2)\n",
    "        elif n%2 == 0: \n",
    "            temp[i] = (1/(n/2)) * np.sin(2*np.pi*(n/2)*xx)\n",
    "        i = i+1\n",
    "    x_tilda = temp\n",
    "    return x_tilda\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == fourier_features(np.array([0]), 1)\n",
    "assert 0 == fourier_features(np.array([0]), 2)\n",
    "assert np.allclose(np.array([1, 1]), fourier_features(np.array([0, 0]), 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot of 9 resuting fourier functions.\n",
    "# you don't have to modify this cell\n",
    "train_tmp = np.arange(0, 2 * np.pi, 0.01)\n",
    "question_check = []\n",
    "labels = []\n",
    "for n in range(9):\n",
    "    ffeatures = fourier_features(train_tmp, n)\n",
    "    plt.plot(train_tmp, ffeatures)\n",
    "    question_check.append(ffeatures[11])\n",
    "    labels.append(f\"{n}\")\n",
    "plt.legend(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.b: Feature matrix, calculation of weights and metrics. Regression.\n",
    "For each $k$, compute the *root mean square error* $E_\\text{RMS}=\\sqrt{E(\\mathbf{w})^2/N}$ on both, training and test data, as a function of maximum frequency $k$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "a43aab09716a2199ba3dc93724cf4a10",
     "grade": false,
     "grade_id": "get_feature_matrix",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_feature_matrix(train, max_k):\n",
    "    \"\"\"\n",
    "    Get a feature matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train : array_like\n",
    "        input array of shape (N,).\n",
    "    max_k : int\n",
    "        maximum number of fourier features K.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    features : array_like\n",
    "        resulting features matrix (N,K).\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    features = np.zeros((train.size, max_k))\n",
    "    for k in range(max_k):\n",
    "        features[:,k] = fourier_features(train,k)\n",
    "    return features\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == get_feature_matrix(np.array([0]), 1)\n",
    "assert np.allclose(np.array([[1, 0]]), get_feature_matrix(np.array([0]), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "e6572378fcc73b9d92c85a14e328f232",
     "grade": false,
     "grade_id": "calculate_weights",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weights(train_features, train_labels):\n",
    "    \"\"\"\n",
    "    Weights calculation for regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : array_like\n",
    "        input array of shape (N,K).\n",
    "    labels : array_like\n",
    "        labels of shape (N).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : array_like\n",
    "        resulting weights matrix (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # hint: you can use np.linalg.pinv for this one\n",
    "    # YOUR CODE HERE\n",
    "    \n",
    "    w = np.linalg.pinv(train_features) @ train_labels\n",
    "    return w\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 1 == calculate_weights(np.array([[1]]), np.array([1]))\n",
    "assert np.allclose(\n",
    "    [0.5, 0.5], calculate_weights(np.array([[0, 0], [1, 1]]), np.array([0, 1]))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2363a53b6731260578db151dac619601",
     "grade": false,
     "grade_id": "cell-ab45197360141103",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_rmse(labels, prediction):\n",
    "    \"\"\"\n",
    "    Calculate root mean square metrics.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    labels : array_like\n",
    "        labels of shape (N,).\n",
    "    prediction : array_like\n",
    "        prediction array of shape (N,).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    rmse : float\n",
    "        resulting rmse.\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    E = np.sum(np.square(labels-prediction))\n",
    "    rmse = np.sqrt(E/np.size(labels))\n",
    "    return rmse\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == get_rmse(np.array([1, 1]), np.array([1, 1]))\n",
    "assert 1 == get_rmse(np.array([0, 0]), np.array([1, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "x = np.linspace(0, 1, 1000)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for max_k in range(1, 18, 2):\n",
    "    # calculate features and weights\n",
    "    phi = get_feature_matrix(train_X, max_k)\n",
    "    w = calculate_weights(phi, train_y)\n",
    "\n",
    "    # get predictions\n",
    "    train_prediction = get_feature_matrix(train_X, max_k) @ w\n",
    "    test_prediction = get_feature_matrix(test_X, max_k) @ w\n",
    "    prediction_on_x = get_feature_matrix(x, max_k) @ w\n",
    "\n",
    "    # calculate rmse metrics\n",
    "    train_rmse = get_rmse(train_y, train_prediction)\n",
    "    test_rmse = get_rmse(test_y, test_prediction)\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(f\"Train RMSE = {train_rmse:.2f}, Test RMSE = {test_rmse:.2f}\")\n",
    "\n",
    "    legend = []\n",
    "    legend.append(\"test\")\n",
    "    plt.plot(test_X, test_y, \"bo\", markersize=0.5)\n",
    "    legend.append(\"train\")\n",
    "    plt.plot(train_X, train_y, \"rx\")\n",
    "    legend.append(f\"Model with k = {max_k}\")\n",
    "    plt.plot(x, prediction_on_x, \"g-\")\n",
    "\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Error plot depending on basis functions**\n",
    "\n",
    "What do you observe, why is it happening?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "plt.plot(train_errors, \"r\")\n",
    "plt.plot(test_errors, \"b\")\n",
    "plt.legend([\"train error\", \"test_error\"])\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"k basis functions\")\n",
    "plt.xticks(range(9), list(range(1, 18, 2)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the minimum RMSE on the test set (given k<=17)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "print(f\"Minimum RMSE = {np.min(test_errors):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 3.c: Ridge regression\n",
    "Extend your code to incorporate a prior on the weights of the regression function to perform *Ridge Regression*.\n",
    "Repeat the above tasks with various regularization weights $\\lambda$.\n",
    "Which value gives good results?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "2d3421f357c7b1d2602d4cb5ca517898",
     "grade": false,
     "grade_id": "ridge_regression",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def calculate_weights_ridge_regression(train_features, train_labels, alpha=0.01):\n",
    "    \"\"\"\n",
    "    Simple weights calculation from features and labels, with ridge regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    features : array_like\n",
    "        input array of shape (N,K).\n",
    "    labels : array_like\n",
    "        labels of shape (N).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    w : array_like\n",
    "        resulting weights matrix (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    N,K = np.shape(train_features)\n",
    "    w = np.linalg.inv(train_features.T @ train_features + alpha*np.eye(K)) @ train_features.T @ train_labels\n",
    "    return w\n",
    "    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert 0 == calculate_weights_ridge_regression(np.array([[0]]), np.array([0]))\n",
    "assert 1 == calculate_weights_ridge_regression(np.array([[1]]), np.array([1]), alpha=0)\n",
    "assert 0.5 == calculate_weights_ridge_regression(\n",
    "    np.array([[1]]), np.array([1]), alpha=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "alpha = 0.01\n",
    "x = np.linspace(0, 1, 1000)\n",
    "train_errors_lambda = []\n",
    "test_errors_lambda = []\n",
    "\n",
    "for max_k in range(1, 18, 2):\n",
    "    # calculate features and weights\n",
    "    phi = get_feature_matrix(train_X, max_k)\n",
    "    w = calculate_weights_ridge_regression(phi, train_y, alpha)\n",
    "\n",
    "    # get predictions\n",
    "    train_prediction = get_feature_matrix(train_X, max_k) @ w\n",
    "    test_prediction = get_feature_matrix(test_X, max_k) @ w\n",
    "    prediction_on_x = get_feature_matrix(x, max_k) @ w\n",
    "\n",
    "    # calculate rmse metrics\n",
    "    train_rmse = get_rmse(train_y, train_prediction)\n",
    "    test_rmse = get_rmse(test_y, test_prediction)\n",
    "    train_errors_lambda.append(train_rmse)\n",
    "    test_errors_lambda.append(test_rmse)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(f\"Train RMSE = {train_rmse:.2f}, Test RMSE = {test_rmse:.2f}\")\n",
    "\n",
    "    legend = []\n",
    "    legend.append(\"test\")\n",
    "    plt.plot(test_X, test_y, \"bo\", markersize=0.5)\n",
    "    legend.append(\"train\")\n",
    "    plt.plot(train_X, train_y, \"rx\")\n",
    "    legend.append(f\"Model with k = {max_k}\")\n",
    "    plt.plot(x, prediction_on_x, \"g-\")\n",
    "\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "print(f\"Minimum RMSE for ridge regression = {np.min(test_errors_lambda):.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "plt.plot(train_errors, \"r\")\n",
    "plt.plot(test_errors, \"b\")\n",
    "plt.plot(train_errors_lambda, \"--r\")\n",
    "plt.plot(test_errors_lambda, \"--b\")\n",
    "plt.legend(\n",
    "    [\n",
    "        \"train error\",\n",
    "        \"test error\",\n",
    "        \"train error with regularization\",\n",
    "        \"test error with regularization\",\n",
    "    ]\n",
    ")\n",
    "plt.ylabel(\"RMSE\")\n",
    "plt.xlabel(\"k basis functions\")\n",
    "plt.xticks(range(9), list(range(1, 18, 2)))\n",
    "plt.ylim([0, 1])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What happens for the $k > 15$, and $\\alpha = 0.01$:\n",
    "\n",
    "1. train error > train error w regularization > test error > test error w regularization\n",
    "2. test error > test error w regularization > train error > train error w regularization\n",
    "3. test error w regularization > test error > train error > train error w regularization\n",
    "4. test errr > test error w regularization > train error w regularization > train error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Solution: \n",
    "    4. test errr > test error w regularization > train error w regularization > train error"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4 Kernel Ridge Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the lecture it has been discussed that *Ridge Regression* can be combined with *kernels*.\n",
    "Extend the regression for the previous task such that it makes use of a kernel. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.a: Ridge regression with exponential kernel\n",
    "Squared exponential kernel: \n",
    "$$\\begin{aligned}\n",
    "                k(x,y) = \\exp\\left( - \\frac{( x - y )^2}{2l^2} \\right)\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "31cd530ce51a4bb116186eab6113ed3d",
     "grade": false,
     "grade_id": "exponential_kernel",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def exponential_kernel(x, y, length_scale=0.4):\n",
    "    \"\"\"\n",
    "    Calculation of exponential kernel based on inputs x and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        input array of shape (N).\n",
    "    y : array_like\n",
    "        labels of shape (N).\n",
    "    length_scale : float\n",
    "        parameter of exponential kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kernel : array_like\n",
    "        resulting kernel matrix (N,N).\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    Nx = np.size(x)\n",
    "    Ny = np.size(y)\n",
    "    kernel = np.zeros((Nx,Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            kernel[i,j] = np.exp(-np.power((x[i]-y[j]),2)/(2*length_scale*length_scale))\n",
    "    return kernel\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "d599630b945f28f570e18e729e7bd434",
     "grade": false,
     "grade_id": "get_matrix_a",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def get_matrix_a(kernel, train_labels, alpha=0.1):\n",
    "    \"\"\"\n",
    "    Calculation of representation matrix.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    kernel : array_like\n",
    "        input array of shape (N,K).\n",
    "    labels : array_like\n",
    "        labels of shape (N).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    a : array_like\n",
    "        resulting solution to dual representation matrix (N,).\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    N, K = np.shape(kernel)\n",
    "    temp_kernel = kernel + alpha*np.eye(N,K,dtype='float')\n",
    "    a = np.linalg.inv(temp_kernel) @ np.float64(np.atleast_2d(train_labels)).T\n",
    "    return a\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "9c07fb08df22d3f23abb2abc6233a32b",
     "grade": false,
     "grade_id": "estimate_at_location",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def estimate_at_location(test, train, a, kernel_function, kernel_parameters):\n",
    "    \"\"\"\n",
    "    Simple weights calculation from features and labels, with ridge regression.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    test : array_like\n",
    "        input test data of shape (M,);\n",
    "    train : array_like\n",
    "        input train data of shape (N,);\n",
    "    a : array_like\n",
    "        dual representation matrix (N,);\n",
    "    kernel_function : Callable\n",
    "        desired kernel funciton. Default: polynomial_kernel;\n",
    "    kernel_parameters : float\n",
    "        kernel paramters for `kernel_function`.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    prediction : array_like\n",
    "        resulting estimation (M,).\n",
    "\n",
    "    \"\"\"\n",
    "    # YOUR CODE HERE\n",
    "    prediction = kernel_function(test,train,kernel_parameters) @ a\n",
    "\n",
    "    return prediction\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "x = np.linspace(0, 1, 1000)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for kernel_parameters in np.linspace(0.3, 1.5, 5):\n",
    "    # compute kernel\n",
    "    kernel_matrix = exponential_kernel(train_X, train_X, length_scale=kernel_parameters)\n",
    "    # compute solution for dual representation\n",
    "    a = get_matrix_a(kernel_matrix, train_y, 0.001)\n",
    "\n",
    "    # compute estimate at sampled locations\n",
    "    train_prediction = estimate_at_location(\n",
    "        train_X,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=exponential_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "\n",
    "    test_prediction = estimate_at_location(\n",
    "        test_X,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=exponential_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "\n",
    "    prediction = estimate_at_location(\n",
    "        x,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=exponential_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "\n",
    "    # calculate rmse metrics\n",
    "    train_rmse = get_rmse(train_y, train_prediction.ravel())\n",
    "    test_rmse = get_rmse(test_y, test_prediction.ravel())\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(f\"Train RMSE = {train_rmse:.2f}, Test RMSE = {test_rmse:.2f}\")\n",
    "\n",
    "    legend = []\n",
    "    legend.append(\"test\")\n",
    "    plt.plot(test_X, test_y, \"bo\", markersize=0.5)\n",
    "    legend.append(\"train\")\n",
    "    plt.plot(train_X, train_y, \"rx\")\n",
    "    legend.append(f\"Model with k = {kernel_parameters}\")\n",
    "    plt.plot(x, prediction, \"g-\")\n",
    "\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the minimum RMSE on the test set for ridge regression with exponential kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "print(f\"Minimum RMSE for ridge regression = {np.min(test_errors):.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 4.b: Ridge regression with polynomial kernel\n",
    "Exchange the kernel for the polynomial kernel: \n",
    "$$\\begin{aligned}\n",
    "    k(x,y) = \\left(x * y +1 \\right)^d\n",
    "\\end{aligned}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "deletable": false,
    "nbgrader": {
     "cell_type": "code",
     "checksum": "7c863740e05fc6a64a18bbb32a697ec0",
     "grade": false,
     "grade_id": "polynomial_kernel",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "def polynomial_kernel(x, y, d=5):\n",
    "    \"\"\"\n",
    "    Calculation of polynomial kernel based on inputs x and y.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    x : array_like\n",
    "        input array of shape (N).\n",
    "    y : array_like\n",
    "        second input of shape (N).\n",
    "    d : float\n",
    "        parameter of polynomial kernel.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    kernel : array_like\n",
    "        resulting kernel matrix (N,N).\n",
    "\n",
    "    \"\"\"\n",
    "    Nx = np.size(x)\n",
    "    Ny = np.size(y)\n",
    "    kernel = np.zeros((Nx,Ny))\n",
    "    for i in range(Nx):\n",
    "        for j in range(Ny):\n",
    "            kernel[i,j] = np.power((x[i]*y[j]+1),d)\n",
    "    return kernel\n",
    "    \n",
    "    # YOUR CODE HERE\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.linspace(0, 1, 1000)\n",
    "train_errors = []\n",
    "test_errors = []\n",
    "\n",
    "for kernel_parameters in np.linspace(2, 20, 6):\n",
    "    # compute kernel\n",
    "    kernel_matrix = polynomial_kernel(train_X, train_X, d=kernel_parameters)\n",
    "    # compute solution for dual representation\n",
    "    a = get_matrix_a(kernel_matrix, train_y, 0.001)\n",
    "\n",
    "    # compute estimate at sampled locations\n",
    "    train_prediction = estimate_at_location(\n",
    "        train_X,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=polynomial_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "    test_prediction = estimate_at_location(\n",
    "        test_X,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=polynomial_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "    prediction = estimate_at_location(\n",
    "        x,\n",
    "        train_X,\n",
    "        a,\n",
    "        kernel_function=polynomial_kernel,\n",
    "        kernel_parameters=kernel_parameters,\n",
    "    )\n",
    "\n",
    "    # calculate rmse metrics\n",
    "    train_rmse = get_rmse(train_y, train_prediction.ravel())\n",
    "    test_rmse = get_rmse(test_y, test_prediction.ravel())\n",
    "    train_errors.append(train_rmse)\n",
    "    test_errors.append(test_rmse)\n",
    "\n",
    "    # plotting\n",
    "    plt.title(f\"Train RMSE = {train_rmse:.2f}, Test RMSE = {test_rmse:.2f}\")\n",
    "\n",
    "    legend = []\n",
    "    legend.append(\"test\")\n",
    "    plt.plot(test_X, test_y, \"bo\", markersize=0.5)\n",
    "    legend.append(\"train\")\n",
    "    plt.plot(train_X, train_y, \"rx\")\n",
    "    legend.append(f\"Model with k = {kernel_parameters}\")\n",
    "    plt.plot(x, prediction, \"g-\")\n",
    "\n",
    "    plt.xlim([0, 1])\n",
    "    plt.ylim([-2, 2])\n",
    "    plt.legend(legend)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What is the minimum RMSE on the test set for ridge regression with exponential kernel?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# you don't have to modify this cell\n",
    "print(f\"Minimum RMSE for ridge regression = {np.min(test_errors):.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "384px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
